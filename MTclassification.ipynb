{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MTclassification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3QjS4ryuMyu"
      },
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install --upgrade nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWApj7UTvSI1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpAQCpmA8EzZ"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaTDO6fEvQrY"
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate import bleu\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.translate.nist_score import sentence_nist\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LBEbQxzZ7lE"
      },
      "source": [
        "def process(words):\n",
        "  words = words.replace(\"<br />\", \" \").rstrip()\n",
        "  temp = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = words.translate(temp)\n",
        "  # words = words.lower()\n",
        "  words = words.split()\n",
        "  words = [word for word in words if word not in stopwords]\n",
        "  processed_words = ' '.join(words)\n",
        "  return processed_words\n",
        "\n",
        "def strip_punc(s):\n",
        "  return s.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def set_stopwords():\n",
        "  stopwords = open(\"/content/drive/My Drive/translations/stopwords.en.txt\", \"r\", encoding=\"utf8\")\n",
        "  words = stopwords.read().split(\"\\n\")\n",
        "  stopwords.close()\n",
        "  return words"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFGuo7hg8tS1"
      },
      "source": [
        "def build_matrix(cols,data):\n",
        "  n = data.shape[0]\n",
        "  X = np.zeros((n,1))\n",
        "  vec_cols = []\n",
        "  for col in cols:\n",
        "    if col in vec_cols:\n",
        "      array = np.asarray(list(data[col]))\n",
        "      X = np.c_[ X, array ] \n",
        "    else:\n",
        "      array = np.asarray(data[col])\n",
        "      array = array.reshape(array.shape[0],-1)\n",
        "      X = np.c_[ X, array ] \n",
        "  return X[:,1:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0AAWklW9mB8"
      },
      "source": [
        "def cosine_similarity(A, B):\n",
        "  return (np.dot(A,B))/(np.linalg.norm(A)*np.linalg.norm(B))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsUZmDX0vWM6"
      },
      "source": [
        "def load_data(directory):\n",
        "\n",
        "  ############ Load training data\n",
        "\n",
        "  sources = []\n",
        "  references = []\n",
        "  candidates = []\n",
        "  scores = []\n",
        "  labels = []\n",
        "  targets = []\n",
        "\n",
        "  with open(f\"{directory}/train.txt\", encoding=\"utf-8\") as f:\n",
        "    reader = f.readlines()\n",
        "    for count,row in enumerate(reader):\n",
        "      if count % 6 == 0:\n",
        "        sources.append(row.strip('\\n'))\n",
        "      elif count % 6 == 1:\n",
        "        references.append( strip_punc(row.strip('\\n')) )  \n",
        "      elif count % 6 == 2:\n",
        "        candidates.append( strip_punc(row.strip('\\n')) ) \n",
        "      elif count % 6 == 3:\n",
        "        scores.append(row.strip('\\n'))\n",
        "      elif count % 6 == 4:\n",
        "        labels.append(row.strip('\\n'))\n",
        "        if (row.strip('\\n') == 'H'):\n",
        "          targets.append(1)\n",
        "        else:\n",
        "          targets.append(0)\n",
        "\n",
        "  dict = {\n",
        "      'source':sources,\n",
        "      'reference':references,\n",
        "      'candidate':candidates,\n",
        "      'bleu_uni':scores,\n",
        "      'label':labels,\n",
        "      'target':targets\n",
        "          }\n",
        "  train_data = pd.DataFrame(dict)\n",
        "\n",
        "  ############ Load test data\n",
        "\n",
        "  sources = []\n",
        "  references = []\n",
        "  candidates = []\n",
        "  scores = []\n",
        "  labels = []\n",
        "  targets = []\n",
        "\n",
        "  with open(f\"{directory}/test.txt\", encoding=\"utf-8\") as f:\n",
        "  \n",
        "    reader = f.readlines()\n",
        "    for count,row in enumerate(reader):\n",
        "      if count % 6 == 0:\n",
        "        sources.append(row.strip('\\n'))\n",
        "      elif count % 6 == 1:\n",
        "        references.append( strip_punc(row.strip('\\n')) )\n",
        "      elif count % 6 == 2:\n",
        "        candidates.append( strip_punc(row.strip('\\n')) )\n",
        "      elif count % 6 == 3:\n",
        "        scores.append(row.strip('\\n'))\n",
        "      elif count % 6 == 4:\n",
        "        labels.append(row.strip('\\n'))\n",
        "        if (row.strip('\\n') == 'H'):\n",
        "          targets.append(1)\n",
        "        else:\n",
        "          targets.append(0)\n",
        "    \n",
        "  dict = {\n",
        "      'source':sources,\n",
        "      'reference':references,\n",
        "      'candidate':candidates,\n",
        "      'bleu_uni':scores,\n",
        "      'label':labels,\n",
        "      'target':targets\n",
        "          }\n",
        "  test_data = pd.DataFrame(dict)\n",
        "\n",
        "  return train_data, test_data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7jimxKiP5vS"
      },
      "source": [
        "\n",
        "############################################################\n",
        "############ Begin execution\n",
        "\n",
        "sbert_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiYDzHkXUQ-Q"
      },
      "source": [
        "############ Load data from files\n",
        "\n",
        "stopwords = set_stopwords()\n",
        "directory = '/content/drive/My Drive/translations'\n",
        "train_data, test_data = load_data(directory)\n",
        "\n",
        "############ Form custom embedding features for train, test\n",
        "\n",
        "dfs = [train_data, test_data]\n",
        "\n",
        "for df in dfs:\n",
        "\n",
        "  cos_s_r = []\n",
        "  cos_s_c = []\n",
        "  cos_c_r = []\n",
        "\n",
        "  for i in range(len(df.index)):\n",
        "\n",
        "    row = df.loc[i]\n",
        "\n",
        "    text = row['source']\n",
        "    sour_vec = sbert_model.encode([text])[0]\n",
        "\n",
        "    text = process(row['reference'])\n",
        "    ref_vec = sbert_model.encode([text])[0]\n",
        "\n",
        "    text = process(row['candidate'])\n",
        "    can_vec = sbert_model.encode([text])[0]\n",
        "\n",
        "    cos_s_r.append( cosine_similarity(sour_vec, ref_vec) )\n",
        "    cos_s_c.append( cosine_similarity(sour_vec, can_vec) )\n",
        "    cos_c_r.append( cosine_similarity(can_vec, ref_vec) )\n",
        "\n",
        "  df['cos_s_r'] = cos_s_r\n",
        "  df['cos_s_c'] = cos_s_c\n",
        "  df['cos_c_r'] = cos_c_r"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sDFGaEVzVq8"
      },
      "source": [
        "############ Compute additional MT Scores for train, test \n",
        "\n",
        "smoother = SmoothingFunction().method4\n",
        "\n",
        "for df in dfs:\n",
        "\n",
        "  bleu_sm = []\n",
        "  met = []\n",
        "  nist = []\n",
        "\n",
        "  for i in range(len(df.index)):\n",
        "\n",
        "    row = df.loc[i]\n",
        "\n",
        "    ref_tokens = word_tokenize(row['reference'])\n",
        "    can_tokens = word_tokenize(row['candidate'])\n",
        "    bleu_sm.append( sentence_bleu([ref_tokens], can_tokens, smoothing_function=smoother) )\n",
        "    met.append( nltk.translate.meteor_score.meteor_score([row['reference']], row['candidate']) )\n",
        "    nist.append( sentence_nist([ref_tokens], can_tokens, 2) )\n",
        "\n",
        "  df['bleu_sm'] = bleu_sm\n",
        "  df['met'] = met\n",
        "  df['nist'] = nist"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "e1qh4xZYHacn",
        "outputId": "de194fea-aaf9-4cea-f4e4-6cb6389ba458"
      },
      "source": [
        "############ Evaluate various models on various feature selections\n",
        "\n",
        "col_set = []\n",
        "col_set.append(['bleu_uni'])\n",
        "col_set.append(['bleu_sm'])\n",
        "col_set.append(['met'])\n",
        "col_set.append(['nist'])\n",
        "col_set.append(['bleu_uni','bleu_sm','met','nist'])\n",
        "col_set.append(['cos_s_r'])\n",
        "col_set.append(['cos_s_c'])\n",
        "col_set.append(['cos_c_r'])\n",
        "col_set.append(['cos_s_r','cos_s_c','cos_c_r'])\n",
        "col_set.append(['bleu_uni','cos_s_r','cos_s_c','cos_c_r'])\n",
        "col_set.append(['bleu_uni','nist','cos_s_r','cos_s_c','cos_c_r'])\n",
        "col_set.append(['bleu_uni','bleu_sm','met','nist','cos_s_r','cos_s_c','cos_c_r'])\n",
        "col_set.append(['bleu_uni','nist','cos_c_r'])\n",
        "\n",
        "result_data = []\n",
        "\n",
        "with open(\"output.csv\", \"w\") as f:\n",
        "\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['features','model','f1','accuracy'])\n",
        "\n",
        "  for col in col_set:\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    X_train = build_matrix(col,train_data).astype('float32')\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test = build_matrix(col,test_data).astype('float32')\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    y_train = np.asarray(train_data['target'])\n",
        "    y_test = np.asarray(test_data['target'])\n",
        "\n",
        "    ###### SVC Linear\n",
        "\n",
        "    model_parameters = {\n",
        "      'kernel': ['linear'],\n",
        "        'C': [0.1, 0.5, 1, 5, 10, 50, 100]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(SVC(), model_parameters, cv=5, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'SVC linear',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])\n",
        "\n",
        "    ###### SVC RBF\n",
        "\n",
        "    model_parameters = {\n",
        "      'kernel': ['rbf'],\n",
        "        'C': [0.1, 0.5, 1, 5, 10, 50, 100],\n",
        "        'gamma': [0.1, 0.5, 1, 3, 6, 10],\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(SVC(), model_parameters, cv=5, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'SVC RBF',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])\n",
        "\n",
        "    ###### Logistic Regression\n",
        "\n",
        "    model_parameters = {\n",
        "        'C': [0.1, 0.5, 1, 5, 10, 50, 100],\n",
        "        'max_iter': [1000]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(LogisticRegression(), model_parameters, cv=5, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'logistic regression',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])\n",
        "\n",
        "    ##### KNN\n",
        "\n",
        "    model_parameters = {\n",
        "      'algorithm': ['auto'],\n",
        "        'n_neighbors': range(1, 51),\n",
        "        'leaf_size': range(5, 61, 5)\n",
        "    }\n",
        "    grid_search = GridSearchCV(KNeighborsClassifier(), model_parameters, cv=5, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'KNN',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])\n",
        "\n",
        "    ##### Decision Tree\n",
        "\n",
        "    model_parameters = {\n",
        "        'max_depth': range(1, 51),\n",
        "        'min_samples_split': range(2, 11)\n",
        "    }\n",
        "    grid_search = GridSearchCV(DecisionTreeClassifier(), model_parameters, cv=5, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'Decision Tree',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])\n",
        "\n",
        "    ##### MLP\n",
        "\n",
        "    model_parameters = {\n",
        "        'solver': ['lbfgs'], \n",
        "        'max_iter': [750,1500], \n",
        "        'alpha': 10.0 ** -np.arange(1, 7), \n",
        "        'hidden_layer_sizes':np.arange(12, 20), \n",
        "        'random_state':[0,4,8]\n",
        "        }\n",
        "    \n",
        "    grid_search = GridSearchCV(neural_network.MLPClassifier(), model_parameters, n_jobs=-1, scoring=\"f1\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    accuracy = 1-(np.mean( np.abs(y_pred - y_test) ) )\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    result_data.append([(' ').join(col),'MLP',f1,accuracy])\n",
        "    writer.writerow(result_data[-1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2a2c30a79a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoXca89az-O7"
      },
      "source": [
        "############ Output summary CSV\n",
        "\n",
        "results = dict()\n",
        "\n",
        "for result in result_data:\n",
        "  features = result[0]\n",
        "  model = result[1]\n",
        "  f1 = result[2]\n",
        "  acc = result[3]\n",
        "\n",
        "  if features not in results:\n",
        "    results[features] = dict()\n",
        "    results[features]['best_f1_model'] = ''\n",
        "    results[features]['best_f1_score'] = 0.0\n",
        "    results[features]['average_f1_score'] = 0.0\n",
        "    results[features]['average_acc_score'] = 0.0\n",
        "    results[features]['total_seen'] = 0\n",
        "    results[features]['total_f1_score'] = 0.0\n",
        "    results[features]['total_acc_score'] = 0.0\n",
        "\n",
        "  results[features]['total_seen'] += 1\n",
        "  results[features]['total_f1_score'] += f1\n",
        "  results[features]['total_acc_score'] += acc\n",
        "  results[features]['average_f1_score'] = (results[features]['total_f1_score']/results[features]['total_seen'])\n",
        "  results[features]['average_acc_score'] = (results[features]['total_acc_score']/results[features]['total_seen'])\n",
        "\n",
        "  if f1 > results[features]['best_f1_score']:\n",
        "    results[features]['best_f1_score'] = f1\n",
        "    results[features]['best_f1_model'] = model\n",
        "\n",
        "with open(\"output_agg.csv\", \"w\") as f:\n",
        "\n",
        "  writer = csv.writer(f)\n",
        "\n",
        "  key1 = list(results.keys())[0]\n",
        "  col_names = list(results[features].keys())\n",
        "  col_names.insert(0,'features')\n",
        "  writer.writerow(col_names[0:5])\n",
        "  \n",
        "  for features in results.keys():\n",
        "\n",
        "    nums = list(results[features].values())\n",
        "    nums.insert(0,features)\n",
        "    writer.writerow(nums[0:5])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}